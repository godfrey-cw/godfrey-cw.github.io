<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Charles Godfrey | Home Page</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Charles Godfrey" />
<meta name="author" content="Charles Godfrey" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Home Page" />
<meta property="og:description" content="Home Page" />
<meta property="og:site_name" content="Charles Godfrey" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Charles Godfrey" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"Charles Godfrey"},"description":"Home Page","headline":"Charles Godfrey","name":"Charles Godfrey","url":"/"}</script>
<!-- End Jekyll SEO tag -->
<link id="main-stylesheet" rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Charles Godfrey" /><!-- mathjax -->
<script src="/assets/js/mathjax-config.js" id="MathJax-config" defer></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" defer></script>
<!-- redirect stuff -->
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/">Charles Godfrey</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/resume.html">Resume</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home"><p>I am a machine learning scientist at <a href="https://www.thomsonreuters.com/en/careers/our-jobs/join-thomson-reuters-labs.html">Thomson Reuters
Labs</a>,
working on AI agents for knowledge workers. My focus areas include evaluations
(rubric design for human expert evaluation, curation of benchmarking datasets,
“auto”-evaluation a.k.a. LLM-as-judge) and patterns of large language model
agent design. In prior work at TR Labs I have worked on machine learning models
embedded as components of search systems, including re-ranking, dense retrieval
(a.k.a. vector search) and retrieval-augmented generation.</p>

<p>Previously I was a postdoctoral research associate at <a href="https://www.pnnl.gov/">Pacific Northwest
National Lab</a>, working in <a href="https://scholar.google.com/citations?user=sxRHY7MAAAAJ">Tegan
Emerson</a>’s Math of Data
Science group where my mentor was <a href="https://hkvinge.github.io/">Henry Kvinge</a>.
Before that I completed a PhD in mathematics (algebraic geometry) at the
University of Washington, advised by <a href="http://sites.math.washington.edu/~kovacs/current/index.html">Sándor
Kovács</a>.</p>

<h1 id="research">Research</h1>

<p>I am interested in holistic evaluation of deep learning models, including bias,
robustness, explainability and interpretability, and post-hoc analysis of
learned features (e.g. representation (dis)similarity metrics).
<!-- For the most
part I have worked with computer vision classifiers/segmenters, but more recently I have
experimented with natural language models, of both the generation (GPT) and
understanding (BERT) varieties. --></p>

<p>My pure math research focused on birational geometry and singularities, mostly in
positive and mixed characteristic.</p>

<h2 id="publications">Publications</h2>

<h3 id="main-track">Main Track</h3>

<ol>
  <li>Davis Brown, Charles Godfrey, Nicholas Konz, Jonathan Tu and Henry Kvinge.
<a href="https://aclanthology.org/2023.emnlp-main.403/">Understanding the Inner-workings of Language Models Through Representation
Dissimilarity</a>.
In <em>EMNLP 2023</em>.</li>
  <li>Kelsey Lieberman, James Diffenderfer, Charles Godfrey and Bhavya Kailkhura.
 <a href="https://arxiv.org/abs/2307.08657">Neural Image Compression: Generalization, Robustness, and Spectral
 Biases</a>. In <em>NeurIPS 2023</em> (was
  also selected for an oral presentation at <em>ICML 2023 Workshop Neural
 Compression: From Information Theory to Applications</em>). Code available at
  <a href="https://github.com/klieberman/ood_nic">github.com/klieberman/ood_nic</a></li>
  <li>Charles Godfrey, Davis Brown (equal contribution), Tegan Emerson and Henry
  Kvinge. <a href="https://papers.nips.cc/paper_files/paper/2022/hash/4df3510ad02a86d69dc32388d91606f8-Abstract-Conference.html">On the Symmetries of Deep Learning Models and their Internal
  Representations</a>.
  In <em>NeurIPS 2022</em>. Code available at
  <a href="https://github.com/pnnl/modelsym">github.com/pnnl/modelsym</a>.</li>
</ol>

<h3 id="workshop">Workshop</h3>

<ol>
  <li>Nicholas Konz, Charles Godfrey, Madelyn Shapiro, Jonathan Tu, Henry
 Kvinge and  Davis Brown. <a href="https://arxiv.org/abs/2310.03149">Attributing Learned Concepts in Neural Networks to
 Training Data</a>. In <em>The 1st Workshop on
 Attributing Model Behavior at Scale at NeurIPS 2023</em>, <strong>selected for oral presentation</strong>.</li>
  <li>Charles Godfrey, Henry Kvinge, Elise Bishoff, Myles Mckay, Davis Brown, Tim
 Doster and Eleanor Byler. <a href="https://arxiv.org/abs/2303.14173">How many dimensions are required to find an
 adversarial example?</a> In <em>The 3rd Workshop
 of Adversarial Machine Learning on Computer Vision at CVPR 2023</em>, <strong>selected
 for oral presentation.</strong></li>
  <li>Charles Godfrey, Michael Rawson, Henry Kvinge and Davis Brown. <a href="https://arxiv.org/abs/2303.06208">Fast
computation of permutation equivariant layers with the partition
algebra</a>. In <em>ICLR 2023 Workshop on Physics
for Machine Learning</em>.</li>
  <li>Davis Brown, Charles Godfrey (equal contribution), Cody Nizinski, Jonathan
Tu, Henry Kvinge. <a href="https://arxiv.org/abs/2303.00046">Robustness of edited neural
networks</a>. In <em>ICLR 2023 Workshop on
Mathematical and Empirical Understanding of Foundation Models</em>.</li>
  <li>Henry Kvinge, Davis Brown and Charles Godfrey. <a href="https://arxiv.org/abs/2302.09301">Exploring the Representation
Manifolds of Stable Diffusion Through the Lens of Intrinsic
Dimension</a>. In <em>ICLR 2023 Workshop on
Mathematical and Empirical Understanding of Foundation Models</em>, <a href="https://thegradientpub.substack.com/p/challenges-for-personal-robotics?utm_source=profile&amp;utm_medium=reader2"><strong>featured
in The
Gradient</strong></a>.</li>
  <li>Charles Godfrey, Elise Bishoff, Myles McKay and Eleanor Byler. <a href="https://arxiv.org/abs/2309.12463">Impact of architecture on robustness and interpretability of multispectral deep neural networks</a>. In <em>SPIE Defense + Commercial Sensing 2023</em>.</li>
  <li>Elizabeth Coda, Nico Courts, Colby Wight, Loc Truong, WoongJo Choi, Charles
Godfrey, Tegan Emerson, Keerti Kappagantula and Henry Kvinge. <a href="https://arxiv.org/abs/2203.08189">Fiber bundle
morphisms as a framework for modeling many-to-many
maps</a>. In <em>ICLR 2022 Workshop on
Geometrical and Topological Representation Learning</em>.</li>
</ol>

<h2 id="preprints">Preprints</h2>

<ol>
  <li>Charles Godfrey, Ping Nie, Natalia Ostapuk, David Ken, Shang Gao and Souheil Inati. <a href="https://arxiv.org/abs/2505.19334">Likert or Not: LLM Absolute Relevance Judgments on Fine-Grained Ordinal Scales</a> (2025).</li>
  <li><a href="https://arxiv.org/abs/2301.00517">Correspondences in log Hodge cohomology</a> (2023).</li>
  <li>Henry Kvinge, Grayson Jorgenson, Davis Brown, Charles Godfrey and Tegan
Emerson. <a href="https://arxiv.org/abs/2211.10558">Neural frames: A Tool for Studying the Tangent Bundles Underlying
Image Datasets and How Deep Learning Models Process
Them</a> (2022).</li>
  <li>Charles Godfrey, Elise Bishoff, Myles Mckay, Davis Brown, Grayson Jorgenson,
Henry Kvinge and Eleanor Byler. <a href="https://arxiv.org/abs/2210.01257">Testing predictions of representation cost
theory with CNNs</a> (2022). Code available at
<a href="https://github.com/pnnl/frequency_sensitivity">https://github.com/pnnl/frequency_sensitivity</a>.</li>
  <li>Takumi Murayama and Charles Godfrey. <a href="https://arxiv.org/abs/2208.14429">Pure subrings of Du Bois singularities
are Du Bois singularities</a> (2022).</li>
  <li><a href="https://arxiv.org/abs/2207.01142">Higher direct images of ideal sheaves</a> (2022).</li>
</ol>

<!-- 
## Upcoming/Recent Talks

1. June 5-9, 2023: [ICERM Mathematical and Scientific Machine Learning
   Workshop](https://icerm.brown.edu/topical_workshops/tw-23-msml/).  
1. May 4th, 2023: [SPIE Defense + Commercial Sensing
   2023](https://www.spie.org/conferences-and-exhibitions/defense-and-commercial-sensing?SSO=1). -->

<h1 id="axioms">Axioms</h1>

<p>I believe in <a href="http://math.sfsu.edu/federico/">Federico Ardila’s</a>
<a href="https://www.ams.org/publications/journals/notices/201610/rnoti-p1164.pdf">axioms</a>:</p>

<ul>
  <li>
    <p><strong>Axiom 1</strong>. Mathematical potential is distributed equally among different groups, irrespective of geographic, demographic, and economic boundaries.</p>
  </li>
  <li>
    <p><strong>Axiom 2</strong>. Everyone can have joyful, meaningful, and empowering mathematical experiences.</p>
  </li>
  <li>
    <p><strong>Axiom 3</strong>. Mathematics is a powerful, malleable tool that can be shaped and used differently by various communities to serve their needs.</p>
  </li>
  <li>
    <p><strong>Axiom 4</strong>. Every student deserves to be treated with dignity and respect.</p>
  </li>
</ul>

<h1 id="acknowledgments">Acknowledgments</h1>

<p>During the spring of 2019 I was in residence at the Mathematical Sciences
Research Institute in Berkeley, California, supported by the National Science
Foundation under Grant No. 1440140. During the academic year of 2018-2019 I was
supported by the University of Washington Department of Mathematics Graduate
Research Fellowship.</p>



  </div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/%20/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <ul class="contact-list">
          <li class="p-name">Charles Godfrey</li>
          <li><a class="u-email" href="mailto:godfrey.cw@gmail.com">godfrey.cw@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p>Home Page
</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
    <a rel="me" href="" target="_blank" title="">
      <span class="grey fa-brands fa- fa-lg"></span>
    </a>
  </li><li>
    <a rel="me" href="" target="_blank" title="">
      <span class="grey fa-brands fa- fa-lg"></span>
    </a>
  </li><li>
    <a rel="me" href="" target="_blank" title="">
      <span class="grey fa-brands fa- fa-lg"></span>
    </a>
  </li>
  <li>
    <a href="/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
